Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_4 (Conv1D)            (None, 50, 128)           2048      
_________________________________________________________________
conv1d_5 (Conv1D)            (None, 50, 64)            24640     
_________________________________________________________________
dropout_2 (Dropout)          (None, 50, 64)            0         
_________________________________________________________________
max_pooling1d_2 (MaxPooling1 (None, 25, 64)            0         
_________________________________________________________________
conv1d_6 (Conv1D)            (None, 25, 32)            6176      
_________________________________________________________________
conv1d_7 (Conv1D)            (None, 25, 32)            3104      
_________________________________________________________________
dropout_3 (Dropout)          (None, 25, 32)            0         
_________________________________________________________________
max_pooling1d_3 (MaxPooling1 (None, 12, 32)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 384)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 16)                6160      
_________________________________________________________________
dense_4 (Dense)              (None, 16)                272       
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 17        
=================================================================
Total params: 42,417
Trainable params: 42,417
Non-trainable params: 0
_________________________________________________________________

Epoch 1/20
1/1 [==============================] - ETA: 0s - loss: 0.9333
Epoch 00001: val_loss improved from inf to 0.74107, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.9333 - val_loss: 0.7411
Epoch 2/20
1/1 [==============================] - ETA: 0s - loss: 0.7435
Epoch 00002: val_loss improved from 0.74107 to 0.69842, saving model to Models/cnn
1/1 [==============================] - 3s 3s/step - loss: 0.7435 - val_loss: 0.6984
Epoch 3/20
1/1 [==============================] - ETA: 0s - loss: 0.6937
Epoch 00003: val_loss improved from 0.69842 to 0.69309, saving model to Models/cnn
1/1 [==============================] - 3s 3s/step - loss: 0.6937 - val_loss: 0.6931
Epoch 4/20
1/1 [==============================] - ETA: 0s - loss: 0.6908
Epoch 00004: val_loss improved from 0.69309 to 0.69301, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6908 - val_loss: 0.6930
Epoch 5/20
1/1 [==============================] - ETA: 0s - loss: 0.6880
Epoch 00005: val_loss improved from 0.69301 to 0.68913, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6880 - val_loss: 0.6891
Epoch 6/20
1/1 [==============================] - ETA: 0s - loss: 0.6838
Epoch 00006: val_loss improved from 0.68913 to 0.68345, saving model to Models/cnn
1/1 [==============================] - 3s 3s/step - loss: 0.6838 - val_loss: 0.6834
Epoch 7/20
1/1 [==============================] - ETA: 0s - loss: 0.6757
Epoch 00007: val_loss improved from 0.68345 to 0.67704, saving model to Models/cnn
1/1 [==============================] - 3s 3s/step - loss: 0.6757 - val_loss: 0.6770
Epoch 8/20
1/1 [==============================] - ETA: 0s - loss: 0.6760
Epoch 00008: val_loss improved from 0.67704 to 0.67093, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6760 - val_loss: 0.6709
Epoch 9/20
1/1 [==============================] - ETA: 0s - loss: 0.6682
Epoch 00009: val_loss improved from 0.67093 to 0.66582, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6682 - val_loss: 0.6658
Epoch 10/20
1/1 [==============================] - ETA: 0s - loss: 0.6676
Epoch 00010: val_loss improved from 0.66582 to 0.66271, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6676 - val_loss: 0.6627
Epoch 11/20
1/1 [==============================] - ETA: 0s - loss: 0.6673
Epoch 00011: val_loss improved from 0.66271 to 0.66110, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6673 - val_loss: 0.6611
Epoch 12/20
1/1 [==============================] - ETA: 0s - loss: 0.6682
Epoch 00012: val_loss improved from 0.66110 to 0.65982, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6682 - val_loss: 0.6598
Epoch 13/20
1/1 [==============================] - ETA: 0s - loss: 0.6604
Epoch 00013: val_loss did not improve from 0.65982
1/1 [==============================] - 0s 66ms/step - loss: 0.6604 - val_loss: 0.6604
Epoch 14/20
1/1 [==============================] - ETA: 0s - loss: 0.6538
Epoch 00014: val_loss did not improve from 0.65982
1/1 [==============================] - 0s 63ms/step - loss: 0.6538 - val_loss: 0.6623
Epoch 15/20
1/1 [==============================] - ETA: 0s - loss: 0.6574
Epoch 00015: val_loss did not improve from 0.65982
1/1 [==============================] - 0s 62ms/step - loss: 0.6574 - val_loss: 0.6662
Epoch 16/20
1/1 [==============================] - ETA: 0s - loss: 0.6503
Epoch 00016: val_loss did not improve from 0.65982
1/1 [==============================] - 0s 86ms/step - loss: 0.6503 - val_loss: 0.6687
Epoch 17/20
1/1 [==============================] - ETA: 0s - loss: 0.6503
Epoch 00017: val_loss did not improve from 0.65982
1/1 [==============================] - 0s 81ms/step - loss: 0.6503 - val_loss: 0.6710
Epoch 00017: early stopping
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_4 (Conv1D)            (None, 50, 128)           2048      
_________________________________________________________________
conv1d_5 (Conv1D)            (None, 50, 64)            24640     
_________________________________________________________________
dropout_2 (Dropout)          (None, 50, 64)            0         
_________________________________________________________________
max_pooling1d_2 (MaxPooling1 (None, 25, 64)            0         
_________________________________________________________________
conv1d_6 (Conv1D)            (None, 25, 32)            6176      
_________________________________________________________________
conv1d_7 (Conv1D)            (None, 25, 32)            3104      
_________________________________________________________________
dropout_3 (Dropout)          (None, 25, 32)            0         
_________________________________________________________________
max_pooling1d_3 (MaxPooling1 (None, 12, 32)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 384)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 16)                6160      
_________________________________________________________________
dense_4 (Dense)              (None, 16)                272       
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 17        
=================================================================
Total params: 42,417
Trainable params: 42,417
Non-trainable params: 0
_________________________________________________________________

Epoch 1/20
1/1 [==============================] - ETA: 0s - loss: 0.9333
Epoch 00001: val_loss improved from inf to 0.74107, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.9333 - val_loss: 0.7411
Epoch 2/20
1/1 [==============================] - ETA: 0s - loss: 0.7435
Epoch 00002: val_loss improved from 0.74107 to 0.69842, saving model to Models/cnn
1/1 [==============================] - 3s 3s/step - loss: 0.7435 - val_loss: 0.6984
Epoch 3/20
1/1 [==============================] - ETA: 0s - loss: 0.6937
Epoch 00003: val_loss improved from 0.69842 to 0.69309, saving model to Models/cnn
1/1 [==============================] - 3s 3s/step - loss: 0.6937 - val_loss: 0.6931
Epoch 4/20
1/1 [==============================] - ETA: 0s - loss: 0.6908
Epoch 00004: val_loss improved from 0.69309 to 0.69301, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6908 - val_loss: 0.6930
Epoch 5/20
1/1 [==============================] - ETA: 0s - loss: 0.6880
Epoch 00005: val_loss improved from 0.69301 to 0.68913, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6880 - val_loss: 0.6891
Epoch 6/20
1/1 [==============================] - ETA: 0s - loss: 0.6838
Epoch 00006: val_loss improved from 0.68913 to 0.68345, saving model to Models/cnn
1/1 [==============================] - 3s 3s/step - loss: 0.6838 - val_loss: 0.6834
Epoch 7/20
1/1 [==============================] - ETA: 0s - loss: 0.6757
Epoch 00007: val_loss improved from 0.68345 to 0.67704, saving model to Models/cnn
1/1 [==============================] - 3s 3s/step - loss: 0.6757 - val_loss: 0.6770
Epoch 8/20
1/1 [==============================] - ETA: 0s - loss: 0.6760
Epoch 00008: val_loss improved from 0.67704 to 0.67093, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6760 - val_loss: 0.6709
Epoch 9/20
1/1 [==============================] - ETA: 0s - loss: 0.6682
Epoch 00009: val_loss improved from 0.67093 to 0.66582, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6682 - val_loss: 0.6658
Epoch 10/20
1/1 [==============================] - ETA: 0s - loss: 0.6676
Epoch 00010: val_loss improved from 0.66582 to 0.66271, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6676 - val_loss: 0.6627
Epoch 11/20
1/1 [==============================] - ETA: 0s - loss: 0.6673
Epoch 00011: val_loss improved from 0.66271 to 0.66110, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6673 - val_loss: 0.6611
Epoch 12/20
1/1 [==============================] - ETA: 0s - loss: 0.6682
Epoch 00012: val_loss improved from 0.66110 to 0.65982, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6682 - val_loss: 0.6598
Epoch 13/20
1/1 [==============================] - ETA: 0s - loss: 0.6604
Epoch 00013: val_loss did not improve from 0.65982
1/1 [==============================] - 0s 66ms/step - loss: 0.6604 - val_loss: 0.6604
Epoch 14/20
1/1 [==============================] - ETA: 0s - loss: 0.6538
Epoch 00014: val_loss did not improve from 0.65982
1/1 [==============================] - 0s 63ms/step - loss: 0.6538 - val_loss: 0.6623
Epoch 15/20
1/1 [==============================] - ETA: 0s - loss: 0.6574
Epoch 00015: val_loss did not improve from 0.65982
1/1 [==============================] - 0s 62ms/step - loss: 0.6574 - val_loss: 0.6662
Epoch 16/20
1/1 [==============================] - ETA: 0s - loss: 0.6503
Epoch 00016: val_loss did not improve from 0.65982
1/1 [==============================] - 0s 86ms/step - loss: 0.6503 - val_loss: 0.6687
Epoch 17/20
1/1 [==============================] - ETA: 0s - loss: 0.6503
Epoch 00017: val_loss did not improve from 0.65982
1/1 [==============================] - 0s 81ms/step - loss: 0.6503 - val_loss: 0.6710
Epoch 00017: early stopping
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_8 (Conv1D)            (None, 50, 128)           2048      
_________________________________________________________________
conv1d_9 (Conv1D)            (None, 50, 64)            24640     
_________________________________________________________________
dropout_4 (Dropout)          (None, 50, 64)            0         
_________________________________________________________________
max_pooling1d_4 (MaxPooling1 (None, 25, 64)            0         
_________________________________________________________________
conv1d_10 (Conv1D)           (None, 25, 32)            6176      
_________________________________________________________________
conv1d_11 (Conv1D)           (None, 25, 32)            3104      
_________________________________________________________________
dropout_5 (Dropout)          (None, 25, 32)            0         
_________________________________________________________________
max_pooling1d_5 (MaxPooling1 (None, 12, 32)            0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 384)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 16)                6160      
_________________________________________________________________
dense_7 (Dense)              (None, 16)                272       
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 17        
=================================================================
Total params: 42,417
Trainable params: 42,417
Non-trainable params: 0
_________________________________________________________________

Epoch 1/20
1/1 [==============================] - ETA: 0s - loss: 0.7315
Epoch 00001: val_loss improved from inf to 0.71352, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.7315 - val_loss: 0.7135
Epoch 2/20
1/1 [==============================] - ETA: 0s - loss: 0.6923
Epoch 00002: val_loss improved from 0.71352 to 0.69176, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6923 - val_loss: 0.6918
Epoch 3/20
1/1 [==============================] - ETA: 0s - loss: 0.6803
Epoch 00003: val_loss improved from 0.69176 to 0.68660, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6803 - val_loss: 0.6866
Epoch 4/20
1/1 [==============================] - ETA: 0s - loss: 0.6772
Epoch 00004: val_loss improved from 0.68660 to 0.68470, saving model to Models/cnn
1/1 [==============================] - 2s 2s/step - loss: 0.6772 - val_loss: 0.6847
Epoch 5/20
1/1 [==============================] - ETA: 0s - loss: 0.6726
Epoch 00005: val_loss improved from 0.68470 to 0.68101, saving model to Models/cnn
1/1 [==============================] - 3s 3s/step - loss: 0.6726 - val_loss: 0.6810
Epoch 6/20
1/1 [==============================] - ETA: 0s - loss: 0.6714
Epoch 00006: val_loss improved from 0.68101 to 0.67675, saving model to Models/cnn
1/1 [==============================] - 3s 3s/step - loss: 0.6714 - val_loss: 0.6767
Epoch 7/20
1/1 [==============================] - ETA: 0s - loss: 0.6651
Epoch 00007: val_loss improved from 0.67675 to 0.67622, saving model to Models/cnn
1/1 [==============================] - 3s 3s/step - loss: 0.6651 - val_loss: 0.6762
Epoch 8/20
1/1 [==============================] - ETA: 0s - loss: 0.6610
Epoch 00008: val_loss did not improve from 0.67622
1/1 [==============================] - 0s 52ms/step - loss: 0.6610 - val_loss: 0.6771
Epoch 9/20
1/1 [==============================] - ETA: 0s - loss: 0.6562
Epoch 00009: val_loss did not improve from 0.67622
1/1 [==============================] - 0s 61ms/step - loss: 0.6562 - val_loss: 0.6777
Epoch 10/20
1/1 [==============================] - ETA: 0s - loss: 0.6544
Epoch 00010: val_loss did not improve from 0.67622
1/1 [==============================] - 0s 49ms/step - loss: 0.6544 - val_loss: 0.6802
Epoch 11/20
1/1 [==============================] - ETA: 0s - loss: 0.6513
Epoch 00011: val_loss did not improve from 0.67622
1/1 [==============================] - 0s 52ms/step - loss: 0.6513 - val_loss: 0.6844
Epoch 00011: early stopping
